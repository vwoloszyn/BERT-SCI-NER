{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of BERT Based NER using CONLL dataset",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvQ_RWMLbbJR",
        "colab_type": "code",
        "outputId": "bb7ece5d-6d54-4a75-e443-2b6e16ff7924",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "%cd \"/content\"\n",
        "%rm -rf BERT-NER/\n",
        "!git clone https://github.com/vwoloszyn/BERT-NER.git\n",
        "%cd \"/content/BERT-NER\""
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'BERT-NER'...\n",
            "remote: Enumerating objects: 14, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 261 (delta 4), reused 11 (delta 2), pack-reused 247\u001b[K\n",
            "Receiving objects: 100% (261/261), 2.04 MiB | 2.14 MiB/s, done.\n",
            "Resolving deltas: 100% (129/129), done.\n",
            "/content/BERT-NER\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDphixDqmufw",
        "colab_type": "code",
        "outputId": "36e42aa7-01eb-4d32-8cd8-742debc8927e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip3 install -r requirements.txt"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-transformers==1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 2.7MB/s \n",
            "\u001b[?25hCollecting torch==1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/57/d5cceb0799c06733eefce80c395459f28970ebb9e896846ce96ab579a3f1/torch-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (748.8MB)\n",
            "\u001b[K     |████████████████████████████████| 748.9MB 21kB/s \n",
            "\u001b[?25hCollecting seqeval==0.0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/dc/b6/6e58b54c0fa343f9c24969cb887f3e76c13d16dded640cc620a914f27dc4/seqeval-0.0.5-py3-none-any.whl\n",
            "Collecting tqdm==4.31.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/4b/c38b5144cf167c4f52288517436ccafefe9dc01b8d1c190e18a6b154cd4a/tqdm-4.31.1-py2.py3-none-any.whl (48kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.0MB/s \n",
            "\u001b[?25hCollecting nltk==3.4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 36.3MB/s \n",
            "\u001b[?25hCollecting Flask==1.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/93/628509b8d5dc749656a9641f4caf13540e2cdec85276964ff8f43bbb1d3b/Flask-1.1.1-py2.py3-none-any.whl (94kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 11.1MB/s \n",
            "\u001b[?25hCollecting Flask-Cors==3.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/78/38/e68b11daa5d613e3a91e4bf3da76c94ac9ee0d9cd515af9c1ab80d36f709/Flask_Cors-3.0.8-py2.py3-none-any.whl\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers==1.2.0->-r requirements.txt (line 1)) (2019.12.20)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers==1.2.0->-r requirements.txt (line 1)) (1.13.19)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers==1.2.0->-r requirements.txt (line 1)) (1.18.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 38.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers==1.2.0->-r requirements.txt (line 1)) (2.23.0)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 35.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk==3.4.5->-r requirements.txt (line 8)) (1.12.0)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask==1.1.1->-r requirements.txt (line 10)) (1.1.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask==1.1.1->-r requirements.txt (line 10)) (7.1.2)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask==1.1.1->-r requirements.txt (line 10)) (2.11.2)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask==1.1.1->-r requirements.txt (line 10)) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers==1.2.0->-r requirements.txt (line 1)) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.17.0,>=1.16.19 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers==1.2.0->-r requirements.txt (line 1)) (1.16.19)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers==1.2.0->-r requirements.txt (line 1)) (0.10.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers==1.2.0->-r requirements.txt (line 1)) (0.15.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers==1.2.0->-r requirements.txt (line 1)) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers==1.2.0->-r requirements.txt (line 1)) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers==1.2.0->-r requirements.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers==1.2.0->-r requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask==1.1.1->-r requirements.txt (line 10)) (1.1.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.19->boto3->pytorch-transformers==1.2.0->-r requirements.txt (line 1)) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.19->boto3->pytorch-transformers==1.2.0->-r requirements.txt (line 1)) (2.8.1)\n",
            "Building wheels for collected packages: nltk, sacremoses\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.5-cp36-none-any.whl size=1449909 sha256=e129874298eaa480caf027d1a50dae15e14063b0c48cde50693e6bd230a2d553\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=c2ecd7d8906487131ccb9fed555e92195b9c75cf4638f05a17b7bea52aedd3a4\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built nltk sacremoses\n",
            "\u001b[31mERROR: torchvision 0.6.0+cu101 has requirement torch==1.5.0, but you'll have torch 1.2.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: spacy 2.2.4 has requirement tqdm<5.0.0,>=4.38.0, but you'll have tqdm 4.31.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, tqdm, sacremoses, sentencepiece, pytorch-transformers, seqeval, nltk, Flask, Flask-Cors\n",
            "  Found existing installation: torch 1.5.0+cu101\n",
            "    Uninstalling torch-1.5.0+cu101:\n",
            "      Successfully uninstalled torch-1.5.0+cu101\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "  Found existing installation: Flask 1.1.2\n",
            "    Uninstalling Flask-1.1.2:\n",
            "      Successfully uninstalled Flask-1.1.2\n",
            "Successfully installed Flask-1.1.1 Flask-Cors-3.0.8 nltk-3.4.5 pytorch-transformers-1.2.0 sacremoses-0.0.43 sentencepiece-0.1.91 seqeval-0.0.5 torch-1.2.0 tqdm-4.31.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tqdm"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBcE-D7siTnm",
        "colab_type": "text"
      },
      "source": [
        "### **Fine-Tuning:**\n",
        "> For finetuning or training the **bert-base** model run the 'run_ner.py' as command given below.\n",
        "\n",
        "> In below command we have to pass different arguments:\n",
        "   \n",
        "*   '--data_dir' argument required to collect dataset. Pass 'data/' as argument which we can see as directory inside 'BERT-NER' folder for the previous comment and command for 'BERT-NER files' .\n",
        "*   '--bert_model' used to download **pretrained bert base** model of Hugging Face transformers. There are different model-names as suggested by hugging face for argument, here we select 'bert-base-cased'.\n",
        "*   '--task_name' argument used for task to perform. Enter 'ner' as we will train the model for Named Entity Recogintion(NER).\n",
        "*   '--output_dir' argument is for where to store fine-tuned model. We give name 'out_base' for directory  where fine-tuned model stored.\n",
        "*   Other arguments like '--max_seq_length', '--num_train_epochs' and '--warmup_proportion', just give values as suggested in repository.\n",
        "*   For training pass argument '--do_train' and after that evaluating for results pass argument '--do_eval'.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLFE2bp9f7Vv",
        "colab_type": "code",
        "outputId": "4023bba1-09b0-476d-f9b3-d5720d47cb87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python run_ner.py --data_dir=data_scierc/ --bert_model=bert-base-multilingual-cased --task_name=ner --output_dir=out_ner --max_seq_length=64 --do_train --num_train_epochs 5 --do_eval --warmup_proportion=0.1"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "06/04/2020 15:58:12 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "06/04/2020 15:58:13 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729\n",
            "06/04/2020 15:58:14 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json from cache at /root/.cache/torch/pytorch_transformers/45629519f3117b89d89fd9c740073d8e4c1f0a70f9842476185100a8afe715d1.65df3cef028a0c91a7b059e4c404a975ebe6843c71267b67019c0e9cfa8a88f0\n",
            "06/04/2020 15:58:14 - INFO - pytorch_transformers.modeling_utils -   Model config {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"finetuning_task\": \"ner\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 14,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 119547\n",
            "}\n",
            "\n",
            "06/04/2020 15:58:15 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/5b5b80054cd2c95a946a8e0ce0b93f56326dff9fbda6a6c3e02de3c91c918342.7131dcb754361639a7d5526985f880879c9bfd144b65a0bf50590bddb7de9059\n",
            "06/04/2020 15:58:21 - INFO - pytorch_transformers.modeling_utils -   Weights of Ner not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
            "06/04/2020 15:58:21 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in Ner: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "06/04/2020 15:58:23 - INFO - __main__ -   *** Example ***\n",
            "06/04/2020 15:58:23 - INFO - __main__ -   guid: train-0\n",
            "06/04/2020 15:58:23 - INFO - __main__ -   tokens: Multi ##mo ##dal interface ##s require effective pars ##ing and understanding of ut ##teran ##ces whose content is distributed across multiple input modes Johnston 1998 presents an approach in which strategies for multi ##mo ##dal integration are stated declarat ##ive ##ly using uni ##fication based grammar that is used by multi ##dim ##ension ##al chart pars ##er to compose input ##s This\n",
            "06/04/2020 15:58:23 - INFO - __main__ -   input_ids: 101 60929 11033 14555 38819 10107 35742 26874 50918 10230 10111 37149 10108 11735 81057 14585 16879 19509 10124 35123 15130 19865 44870 58686 31844 10363 41175 10151 23068 10106 10319 86985 10142 21247 11033 14555 64861 10301 17067 71702 11942 10454 13382 69191 22060 11610 90960 10189 10124 11031 10155 21247 45094 80236 10415 21746 50918 10165 10114 47241 44870 10107 10747 102\n",
            "06/04/2020 15:58:23 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "06/04/2020 15:58:23 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/04/2020 15:58:23 - INFO - __main__ -   *** Example ***\n",
            "06/04/2020 15:58:23 - INFO - __main__ -   guid: train-1\n",
            "06/04/2020 15:58:23 - INFO - __main__ -   tokens: greatly impact ##s the accuracy that can be achieved by the algorithm ##s we present method of HM ##M training that improve ##s accuracy when training of le ##xica ##l pro ##babil ##ities is uns ##table Finally we show how this new tag ##ger achieve ##s state of the art results in super ##vised non training intensive framework\n",
            "06/04/2020 15:58:23 - INFO - __main__ -   input_ids: 101 48016 21316 10107 10105 100139 10189 10944 10347 28294 10155 10105 73418 10107 11951 12254 22414 10108 109234 11517 15722 10189 33992 10107 100139 10841 15722 10108 10141 53845 10161 11284 104194 17285 10124 15826 30434 51857 11951 11897 14796 10531 10751 37836 11446 43250 10107 11388 10108 10105 11938 17466 10106 25212 46836 10446 15722 73636 54387 102 0 0 0 0\n",
            "06/04/2020 15:58:23 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n",
            "06/04/2020 15:58:23 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/04/2020 15:58:23 - INFO - __main__ -   *** Example ***\n",
            "06/04/2020 15:58:23 - INFO - __main__ -   guid: train-2\n",
            "06/04/2020 15:58:23 - INFO - __main__ -   tokens: This paper address ##es the issue of word sense amb ##igu ##ity in extraction from machine read ##able resources for the construction of large scale knowledge sources We describe two experiments one which ig ##nore ##d word sense distinction ##s resulting in accuracy for sem ##anti ##c classification of verb ##s based on Levin 1993 and one which ex ##plo ##ited word\n",
            "06/04/2020 15:58:23 - INFO - __main__ -   input_ids: 101 10747 17895 32198 10171 10105 15557 10108 12307 15495 10559 86552 11949 10106 81681 10188 21432 24944 13096 25744 10142 10105 13407 10108 12077 19707 22975 19023 12865 30458 10551 56430 10464 10319 23602 99772 10162 12307 15495 44771 10107 26746 10106 100139 10142 11531 24440 10350 15075 10108 62961 10107 11610 10135 62900 10463 10111 10464 10319 11419 46128 77815 12307 102\n",
            "06/04/2020 15:58:23 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "06/04/2020 15:58:23 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/04/2020 15:58:23 - INFO - __main__ -   *** Example ***\n",
            "06/04/2020 15:58:23 - INFO - __main__ -   guid: train-3\n",
            "06/04/2020 15:58:23 - INFO - __main__ -   tokens: are sal ##ient at each point of the discours ##e The distinction among these components is essential to provide an ad ##e ##quate explanation of such discours ##e ph ##enomena as cu ##e phrase ##s referring expressions and inter ##ruption ##s The theory of attention intention and ag ##gregation of ut ##teran ##ces is illustrated in the paper with number of example\n",
            "06/04/2020 15:58:23 - INFO - __main__ -   input_ids: 101 10301 31119 15617 10160 11948 12331 10108 10105 65081 10112 10117 44771 13328 11762 34378 10124 50399 10114 16871 10151 10840 10112 64207 88840 10108 11049 65081 10112 99142 102523 10146 10854 10112 47320 10107 69299 87621 10111 22021 56615 10107 10117 17820 10108 21341 41241 10111 16942 110099 10108 11735 81057 14585 10124 46878 10106 10105 17895 10169 11487 10108 14351 102\n",
            "06/04/2020 15:58:23 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "06/04/2020 15:58:23 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/04/2020 15:58:23 - INFO - __main__ -   *** Example ***\n",
            "06/04/2020 15:58:23 - INFO - __main__ -   guid: train-4\n",
            "06/04/2020 15:58:23 - INFO - __main__ -   tokens: class ##ifier ##s Experimental results show that our system achieve ##s significant improvement on the recognition performance\n",
            "06/04/2020 15:58:23 - INFO - __main__ -   input_ids: 101 13596 95195 10107 56365 17466 11897 10189 17446 11787 43250 10107 17912 70010 10135 10105 31477 14432 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/04/2020 15:58:23 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/04/2020 15:58:23 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/04/2020 15:58:26 - INFO - __main__ -   ***** Running training *****\n",
            "06/04/2020 15:58:26 - INFO - __main__ -     Num examples = 803\n",
            "06/04/2020 15:58:26 - INFO - __main__ -     Batch size = 32\n",
            "06/04/2020 15:58:26 - INFO - __main__ -     Num steps = 125\n",
            "Epoch:   0% 0/5 [00:00<?, ?it/s]\n",
            "Iteration:   0% 0/26 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   4% 1/26 [00:01<00:37,  1.48s/it]\u001b[A\n",
            "Iteration:   8% 2/26 [00:02<00:35,  1.48s/it]\u001b[A\n",
            "Iteration:  12% 3/26 [00:04<00:34,  1.48s/it]\u001b[A\n",
            "Iteration:  15% 4/26 [00:05<00:32,  1.47s/it]\u001b[A\n",
            "Iteration:  19% 5/26 [00:07<00:31,  1.48s/it]\u001b[A\n",
            "Iteration:  23% 6/26 [00:08<00:29,  1.48s/it]\u001b[A\n",
            "Iteration:  27% 7/26 [00:10<00:27,  1.47s/it]\u001b[A\n",
            "Iteration:  31% 8/26 [00:11<00:26,  1.46s/it]\u001b[A\n",
            "Iteration:  35% 9/26 [00:13<00:24,  1.47s/it]\u001b[A\n",
            "Iteration:  38% 10/26 [00:14<00:23,  1.46s/it]\u001b[A\n",
            "Iteration:  42% 11/26 [00:16<00:21,  1.46s/it]\u001b[A\n",
            "Iteration:  46% 12/26 [00:17<00:20,  1.46s/it]\u001b[A\n",
            "Iteration:  50% 13/26 [00:19<00:18,  1.46s/it]\u001b[A\n",
            "Iteration:  54% 14/26 [00:20<00:17,  1.45s/it]\u001b[A\n",
            "Iteration:  58% 15/26 [00:21<00:15,  1.45s/it]\u001b[A\n",
            "Iteration:  62% 16/26 [00:23<00:14,  1.45s/it]\u001b[A\n",
            "Iteration:  65% 17/26 [00:24<00:13,  1.45s/it]\u001b[A\n",
            "Iteration:  69% 18/26 [00:26<00:11,  1.46s/it]\u001b[A\n",
            "Iteration:  73% 19/26 [00:27<00:10,  1.46s/it]\u001b[A\n",
            "Iteration:  77% 20/26 [00:29<00:08,  1.46s/it]\u001b[A\n",
            "Iteration:  81% 21/26 [00:30<00:07,  1.46s/it]\u001b[A\n",
            "Iteration:  85% 22/26 [00:32<00:05,  1.46s/it]\u001b[A\n",
            "Iteration:  88% 23/26 [00:33<00:04,  1.45s/it]\u001b[A\n",
            "Iteration:  92% 24/26 [00:35<00:02,  1.45s/it]\u001b[A\n",
            "Iteration:  96% 25/26 [00:36<00:01,  1.45s/it]\u001b[A\n",
            "Epoch:  20% 1/5 [00:36<02:27, 36.85s/it]\n",
            "Iteration:   0% 0/26 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   4% 1/26 [00:01<00:35,  1.43s/it]\u001b[A\n",
            "Iteration:   8% 2/26 [00:02<00:34,  1.44s/it]\u001b[A\n",
            "Iteration:  12% 3/26 [00:04<00:33,  1.44s/it]\u001b[A\n",
            "Iteration:  15% 4/26 [00:05<00:32,  1.46s/it]\u001b[A\n",
            "Iteration:  19% 5/26 [00:07<00:30,  1.46s/it]\u001b[A\n",
            "Iteration:  23% 6/26 [00:08<00:29,  1.46s/it]\u001b[A\n",
            "Iteration:  27% 7/26 [00:10<00:27,  1.46s/it]\u001b[A\n",
            "Iteration:  31% 8/26 [00:11<00:26,  1.46s/it]\u001b[A\n",
            "Iteration:  35% 9/26 [00:13<00:24,  1.46s/it]\u001b[A\n",
            "Iteration:  38% 10/26 [00:14<00:23,  1.46s/it]\u001b[A\n",
            "Iteration:  42% 11/26 [00:16<00:21,  1.46s/it]\u001b[A\n",
            "Iteration:  46% 12/26 [00:17<00:20,  1.46s/it]\u001b[A\n",
            "Iteration:  50% 13/26 [00:18<00:18,  1.46s/it]\u001b[A\n",
            "Iteration:  54% 14/26 [00:20<00:17,  1.46s/it]\u001b[A\n",
            "Iteration:  58% 15/26 [00:21<00:16,  1.47s/it]\u001b[A\n",
            "Iteration:  62% 16/26 [00:23<00:14,  1.47s/it]\u001b[A\n",
            "Iteration:  65% 17/26 [00:24<00:13,  1.47s/it]\u001b[A\n",
            "Iteration:  69% 18/26 [00:26<00:11,  1.47s/it]\u001b[A\n",
            "Iteration:  73% 19/26 [00:27<00:10,  1.46s/it]\u001b[A\n",
            "Iteration:  77% 20/26 [00:29<00:08,  1.45s/it]\u001b[A\n",
            "Iteration:  81% 21/26 [00:30<00:07,  1.45s/it]\u001b[A\n",
            "Iteration:  85% 22/26 [00:32<00:05,  1.45s/it]\u001b[A\n",
            "Iteration:  88% 23/26 [00:33<00:04,  1.46s/it]\u001b[A\n",
            "Iteration:  92% 24/26 [00:35<00:02,  1.46s/it]\u001b[A\n",
            "Iteration:  96% 25/26 [00:36<00:01,  1.46s/it]\u001b[A\n",
            "Epoch:  40% 2/5 [01:13<01:50, 36.85s/it]\n",
            "Iteration:   0% 0/26 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   4% 1/26 [00:01<00:36,  1.45s/it]\u001b[A\n",
            "Iteration:   8% 2/26 [00:02<00:35,  1.47s/it]\u001b[A\n",
            "Iteration:  12% 3/26 [00:04<00:33,  1.46s/it]\u001b[A\n",
            "Iteration:  15% 4/26 [00:05<00:32,  1.46s/it]\u001b[A\n",
            "Iteration:  19% 5/26 [00:07<00:30,  1.47s/it]\u001b[A\n",
            "Iteration:  23% 6/26 [00:08<00:29,  1.46s/it]\u001b[A\n",
            "Iteration:  27% 7/26 [00:10<00:27,  1.46s/it]\u001b[A\n",
            "Iteration:  31% 8/26 [00:11<00:26,  1.46s/it]\u001b[A\n",
            "Iteration:  35% 9/26 [00:13<00:24,  1.46s/it]\u001b[A\n",
            "Iteration:  38% 10/26 [00:14<00:23,  1.46s/it]\u001b[A\n",
            "Iteration:  42% 11/26 [00:16<00:22,  1.47s/it]\u001b[A\n",
            "Iteration:  46% 12/26 [00:17<00:20,  1.47s/it]\u001b[A\n",
            "Iteration:  50% 13/26 [00:19<00:19,  1.47s/it]\u001b[A\n",
            "Iteration:  54% 14/26 [00:20<00:17,  1.47s/it]\u001b[A\n",
            "Iteration:  58% 15/26 [00:22<00:16,  1.47s/it]\u001b[A\n",
            "Iteration:  62% 16/26 [00:23<00:14,  1.48s/it]\u001b[A\n",
            "Iteration:  65% 17/26 [00:24<00:13,  1.48s/it]\u001b[A\n",
            "Iteration:  69% 18/26 [00:26<00:11,  1.47s/it]\u001b[A\n",
            "Iteration:  73% 19/26 [00:27<00:10,  1.48s/it]\u001b[A\n",
            "Iteration:  77% 20/26 [00:29<00:08,  1.48s/it]\u001b[A\n",
            "Iteration:  81% 21/26 [00:30<00:07,  1.50s/it]\u001b[A\n",
            "Iteration:  85% 22/26 [00:32<00:05,  1.50s/it]\u001b[A\n",
            "Iteration:  88% 23/26 [00:33<00:04,  1.49s/it]\u001b[A\n",
            "Iteration:  92% 24/26 [00:35<00:02,  1.48s/it]\u001b[A\n",
            "Iteration:  96% 25/26 [00:36<00:01,  1.48s/it]\u001b[A\n",
            "Epoch:  60% 3/5 [01:50<01:13, 36.94s/it]\n",
            "Iteration:   0% 0/26 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   4% 1/26 [00:01<00:36,  1.45s/it]\u001b[A\n",
            "Iteration:   8% 2/26 [00:02<00:34,  1.46s/it]\u001b[A\n",
            "Iteration:  12% 3/26 [00:04<00:33,  1.46s/it]\u001b[A\n",
            "Iteration:  15% 4/26 [00:05<00:32,  1.46s/it]\u001b[A\n",
            "Iteration:  19% 5/26 [00:07<00:30,  1.47s/it]\u001b[A\n",
            "Iteration:  23% 6/26 [00:08<00:29,  1.47s/it]\u001b[A\n",
            "Iteration:  27% 7/26 [00:10<00:27,  1.47s/it]\u001b[A\n",
            "Iteration:  31% 8/26 [00:11<00:26,  1.47s/it]\u001b[A\n",
            "Iteration:  35% 9/26 [00:13<00:24,  1.47s/it]\u001b[A\n",
            "Iteration:  38% 10/26 [00:14<00:23,  1.47s/it]\u001b[A\n",
            "Iteration:  42% 11/26 [00:16<00:22,  1.47s/it]\u001b[A\n",
            "Iteration:  46% 12/26 [00:17<00:20,  1.47s/it]\u001b[A\n",
            "Iteration:  50% 13/26 [00:19<00:19,  1.48s/it]\u001b[A\n",
            "Iteration:  54% 14/26 [00:20<00:17,  1.47s/it]\u001b[A\n",
            "Iteration:  58% 15/26 [00:22<00:16,  1.48s/it]\u001b[A\n",
            "Iteration:  62% 16/26 [00:23<00:14,  1.49s/it]\u001b[A\n",
            "Iteration:  65% 17/26 [00:25<00:13,  1.49s/it]\u001b[A\n",
            "Iteration:  69% 18/26 [00:26<00:11,  1.49s/it]\u001b[A\n",
            "Iteration:  73% 19/26 [00:28<00:10,  1.49s/it]\u001b[A\n",
            "Iteration:  77% 20/26 [00:29<00:09,  1.50s/it]\u001b[A\n",
            "Iteration:  81% 21/26 [00:31<00:07,  1.51s/it]\u001b[A\n",
            "Iteration:  85% 22/26 [00:32<00:05,  1.49s/it]\u001b[A\n",
            "Iteration:  88% 23/26 [00:34<00:04,  1.49s/it]\u001b[A\n",
            "Iteration:  92% 24/26 [00:35<00:02,  1.48s/it]\u001b[A\n",
            "Iteration:  96% 25/26 [00:37<00:01,  1.48s/it]\u001b[A\n",
            "Epoch:  80% 4/5 [02:28<00:37, 37.06s/it]\n",
            "Iteration:   0% 0/26 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   4% 1/26 [00:01<00:36,  1.44s/it]\u001b[A\n",
            "Iteration:   8% 2/26 [00:02<00:34,  1.44s/it]\u001b[A\n",
            "Iteration:  12% 3/26 [00:04<00:33,  1.45s/it]\u001b[A\n",
            "Iteration:  15% 4/26 [00:05<00:32,  1.46s/it]\u001b[A\n",
            "Iteration:  19% 5/26 [00:07<00:30,  1.46s/it]\u001b[A\n",
            "Iteration:  23% 6/26 [00:08<00:29,  1.46s/it]\u001b[A\n",
            "Iteration:  27% 7/26 [00:10<00:27,  1.46s/it]\u001b[A\n",
            "Iteration:  31% 8/26 [00:11<00:26,  1.46s/it]\u001b[A\n",
            "Iteration:  35% 9/26 [00:13<00:25,  1.47s/it]\u001b[A\n",
            "Iteration:  38% 10/26 [00:14<00:23,  1.47s/it]\u001b[A\n",
            "Iteration:  42% 11/26 [00:16<00:22,  1.49s/it]\u001b[A\n",
            "Iteration:  46% 12/26 [00:17<00:20,  1.48s/it]\u001b[A\n",
            "Iteration:  50% 13/26 [00:19<00:19,  1.48s/it]\u001b[A\n",
            "Iteration:  54% 14/26 [00:20<00:17,  1.47s/it]\u001b[A\n",
            "Iteration:  58% 15/26 [00:22<00:16,  1.46s/it]\u001b[A\n",
            "Iteration:  62% 16/26 [00:23<00:14,  1.47s/it]\u001b[A\n",
            "Iteration:  65% 17/26 [00:24<00:13,  1.47s/it]\u001b[A\n",
            "Iteration:  69% 18/26 [00:26<00:11,  1.48s/it]\u001b[A\n",
            "Iteration:  73% 19/26 [00:27<00:10,  1.47s/it]\u001b[A\n",
            "Iteration:  77% 20/26 [00:29<00:08,  1.47s/it]\u001b[A\n",
            "Iteration:  81% 21/26 [00:30<00:07,  1.47s/it]\u001b[A\n",
            "Iteration:  85% 22/26 [00:32<00:05,  1.47s/it]\u001b[A\n",
            "Iteration:  88% 23/26 [00:33<00:04,  1.47s/it]\u001b[A\n",
            "Iteration:  92% 24/26 [00:35<00:02,  1.48s/it]\u001b[A\n",
            "Iteration:  96% 25/26 [00:36<00:01,  1.49s/it]\u001b[A\n",
            "Epoch: 100% 5/5 [03:05<00:00, 37.08s/it]\n",
            "06/04/2020 16:01:34 - INFO - __main__ -   *** Example ***\n",
            "06/04/2020 16:01:34 - INFO - __main__ -   guid: dev-0\n",
            "06/04/2020 16:01:34 - INFO - __main__ -   tokens: second type is data driven att ##rib ##utes which are learned from data using dictionary learning methods At ##tri ##but ##e based representation may exhibit high varia ##nce due to noi ##sy and red ##undan ##t att ##rib ##utes We propose disc ##rimi ##nati ##ve and compact att ##rib ##ute based representation by select ##ing sub ##set of disc ##rimi ##nati ##ve\n",
            "06/04/2020 16:01:34 - INFO - __main__ -   input_ids: 101 11132 12807 10124 11165 39803 10788 47116 50808 10319 10301 39496 10188 11165 13382 41399 26901 27413 11699 21570 23170 10112 11610 43847 11387 66890 11846 47645 12150 10850 10114 37390 16105 10111 10680 83722 10123 10788 47116 50808 12865 30027 27224 102422 53718 10612 10111 62474 10788 47116 16808 11610 43847 10155 47054 10230 13987 14488 10108 27224 102422 53718 10612 102\n",
            "06/04/2020 16:01:34 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "06/04/2020 16:01:34 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/04/2020 16:01:34 - INFO - __main__ -   *** Example ***\n",
            "06/04/2020 16:01:34 - INFO - __main__ -   guid: dev-1\n",
            "06/04/2020 16:01:34 - INFO - __main__ -   tokens: ter ##ize the face geometry resulting in smaller search space and better pose ##d system Experiment ##s with both syn ##thetic and real data show that this new algorithm is faster more accurate and more stable than existing ones\n",
            "06/04/2020 16:01:34 - INFO - __main__ -   input_ids: 101 12718 19181 10105 13295 87825 26746 10106 23309 22419 16199 10111 18322 43365 10162 11787 55862 10107 10169 11408 14379 64899 10111 13486 11165 11897 10189 10531 10751 73418 10124 66109 10798 54616 10111 10798 38430 11084 26636 35688 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/04/2020 16:01:34 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/04/2020 16:01:34 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/04/2020 16:01:34 - INFO - __main__ -   *** Example ***\n",
            "06/04/2020 16:01:34 - INFO - __main__ -   guid: dev-2\n",
            "06/04/2020 16:01:34 - INFO - __main__ -   tokens: Pro ##babil ##istic models have been previously shown to be efficient and effective for modeli ##ng and recognition of human motion In particular we focus on methods which represent the human motion model as tri ##ang ##ulated graph Pre ##vio ##us approaches learned models based just on positions and vel ##oci ##ties of the body parts while ig ##nor ##ing their appearance\n",
            "06/04/2020 16:01:34 - INFO - __main__ -   input_ids: 101 14021 104194 29025 22441 10529 10590 17477 19989 10114 10347 65763 10111 26874 10142 77239 10376 10111 31477 10108 14179 30107 10167 15018 11951 23195 10135 27413 10319 30382 10105 14179 30107 13192 10146 15633 11889 37725 81590 35248 18574 10251 63036 39496 22441 11610 12820 10135 23188 10111 21861 59024 14197 10108 10105 14333 15569 11371 23602 36064 10230 10455 19099 102\n",
            "06/04/2020 16:01:34 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "06/04/2020 16:01:34 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/04/2020 16:01:34 - INFO - __main__ -   *** Example ***\n",
            "06/04/2020 16:01:34 - INFO - __main__ -   guid: dev-3\n",
            "06/04/2020 16:01:34 - INFO - __main__ -   tokens: without forcing particular interpretation when their meaning is still not clear\n",
            "06/04/2020 16:01:34 - INFO - __main__ -   input_ids: 101 13663 75098 15018 55760 10841 10455 21157 10124 12647 10472 24866 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/04/2020 16:01:34 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/04/2020 16:01:34 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/04/2020 16:01:34 - INFO - __main__ -   *** Example ***\n",
            "06/04/2020 16:01:34 - INFO - __main__ -   guid: dev-4\n",
            "06/04/2020 16:01:34 - INFO - __main__ -   tokens: The experiments show that the system is able to det ##ect s ##c ##f types with 70 pre ##cision and 66 reca ##ll rate new tool for linguistic anno ##tation of s ##c ##fs in corpus data is also introduced which can considerably alle ##viat ##e the process of obtaining training and test data for sub ##cate ##gor ##ization acquisition\n",
            "06/04/2020 16:01:34 - INFO - __main__ -   input_ids: 101 10117 56430 11897 10189 10105 11787 10124 16197 10114 10349 56906 187 10350 10575 19164 10169 10923 12229 42485 10111 12215 103778 11231 18344 10751 53276 10142 105768 11671 21698 10108 187 10350 25743 10106 75596 11165 10124 10379 17037 10319 10944 91499 10968 110172 10112 10105 15138 10108 107536 15722 10111 15839 11165 10142 13987 26054 28025 19980 41714 102 0 0\n",
            "06/04/2020 16:01:34 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            "06/04/2020 16:01:34 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/04/2020 16:01:35 - INFO - __main__ -   ***** Running evaluation *****\n",
            "06/04/2020 16:01:35 - INFO - __main__ -     Num examples = 345\n",
            "06/04/2020 16:01:35 - INFO - __main__ -     Batch size = 8\n",
            "Evaluating: 100% 44/44 [00:03<00:00, 13.29it/s]\n",
            "06/04/2020 16:01:39 - INFO - __main__ -   \n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "       Task     0.3570    0.3884    0.3720       363\n",
            "   Material     0.3963    0.2876    0.3333       226\n",
            "     Method     0.4696    0.4679    0.4688       545\n",
            "     Metric     0.4286    0.0561    0.0992       107\n",
            "\n",
            "avg / total     0.4198    0.3763    0.3839      1241\n",
            "\n",
            "06/04/2020 16:01:39 - INFO - __main__ -   ***** Eval results *****\n",
            "06/04/2020 16:01:39 - INFO - __main__ -   \n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "       Task     0.3570    0.3884    0.3720       363\n",
            "   Material     0.3963    0.2876    0.3333       226\n",
            "     Method     0.4696    0.4679    0.4688       545\n",
            "     Metric     0.4286    0.0561    0.0992       107\n",
            "\n",
            "avg / total     0.4198    0.3763    0.3839      1241\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRseIPZ1rcEG",
        "colab_type": "code",
        "outputId": "5c422969-7d9a-4de3-8b23-508be521eb99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        }
      },
      "source": [
        "from Prediction_utils_vietnam_labels import Ner\n",
        "# from bert import Ner\n",
        "model = Ner(\"out_ner/\")\n",
        "\n",
        "text= \"Ông Nguyễn Khắc Chúc  đang làm việc tại Đại học Quốc gia Hà Nội. Bà Lan, vợ ông Chúc, cũng làm việc tại đây.\"\n",
        "print(\"Text to predict Entity:\", text)\n",
        "\n",
        "output = model.predict(text)\n",
        "for prediction in output:\n",
        "    print(prediction)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-1be758b981a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mPrediction_utils_vietnam_labels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# from bert import Ner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"out_ner/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"Ông Nguyễn Khắc Chúc  đang làm việc tại Đại học Quốc gia Hà Nội. Bà Lan, vợ ông Chúc, cũng làm việc tại đây.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Prediction_utils_vietnam_labels'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWxL7sv_ui4b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hh_X4djn_N_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r /content/BERT-NER/out_ner/* /content/drive/My\\ Drive/NER_Vietnam_finetune_model/"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}